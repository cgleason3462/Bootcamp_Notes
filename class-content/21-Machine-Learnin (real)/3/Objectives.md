Todays Objectives

* Cross Validation Techniques

    1) K-Fold Cross validation
    https://en.wikipedia.org/wiki/Cross-validation_(statistics)

* Evaluation metrics for classification
    
    1) Accuracy (Correct / Total)

    2) True Positive Rate (TP)

    3) False Positive Rate (FP)

    4) True Negative Rate (TN)

    5) False Negative Rate (FN)

    6) Precision
    Sensitive to False Positive rates
    Example: Cancer diagnosise but had No Cancer
    P = TP / (FP + TP)

    7) Recall
    Sensitive to False Negative rates
    Example: No Cancer diagnosis but had Cancer
    R = TP / (FN + TP)

    8) F1
    Harmonic mean of precsion and recall
    1/F1 = 1/2(1/P + 1/R)
    F1 = 2 P*R / (R + P)

* Classification ML models

    1) K Nearest Neighbor

    2) Support Vector Machine

* Clustering ML model
    
    1) K Means

* Working with Imbalanced datasets

* Resources

    2) K Nearest Neighbor
    Details of KNN algorithm with code walkthrough in Python
    https://youtu.be/AoeEHqVSNOw?t=197

    3) Support Vector Machine
    Applications
    https://youtu.be/N1vOgolbjSc?t=1084
    https://youtu.be/N1vOgolbjSc?t=1106
    https://youtu.be/N1vOgolbjSc?t=1159

    4) K Means Cluster
    Understanding K means algorithm and choosing K
    https://www.datascience.com/blog/k-means-clustering

    5) Precision & Recall
    https://en.wikipedia.org/wiki/Precision_and_recall

    6) F1 Score
    https://en.wikipedia.org/wiki/F1_score
